# Questões Teóricas

4. Explique o dilema entre bias e variância e o seu relacionamento com underfitting e overfitting.
>> O dilema Bias relaciona os erros do modelo, partindo do pressuposto que o modelo seja simples em questão de complexidade, ou seja, erros vindo do próprio modelo por ser de baixa complicação. 
No caso, modelos que tendem a ter um Bias alto, não aprendem de forma adequada os padrões pré-estabelecidos, essa ação se refere ao subajustar que seria o underfitting. 
Em relação a variância, ela se dá a sensibilidade do modelo em relação às variações nos dados que estão sendo treinados. 
Se um modelo possui uma variância muito exacerbada ela se ajusta bem com os dados de treino, porém falha no momento que vai generalizar os novos dados, ocorrendo assim o superajuste, ou overfitting.
A forma como esses dois conceitos se relacionam é de forma resumida, underfitting acontece quando o modelo é muito simples, (ou seja, alto bias), oque faz que sua nitidez final com os dados de treino não sejam tão confiáveis. O outro método, overfitting ocorre quando ao contrário do primeiro, o modelo é extremamente complexo e resulta em bons resultados aos dados de treino, porém tem uma baixa confiabilidade nos novos dados.
/*--------------------------------------------------------------------------------------------------------------------------------------------------------------------------*/
5. Comente sobre a veracidade das afirmações:
a. “Quanto mais variáveis de entrada forem usadas em um modelo de aprendizado de máquina, melhor será a qualidade do modelo”.
>> Nem sempre, por mais que um modelo possua muitas informações, adicionar muitas variáveis pode se tornar um problema, pois essas podem vir a ser irrelevantes para o objetivo final, causando um overfitting, ou , um superajuste, em que o modelo se ajusta tanto aos dados de treino que acaba falhando ao generalizar os novos dados de forma desenfreada. Por isso é mais importante ter variáveis relevantes do que diversas variáveis.

b. “Independente da qualidade, quanto mais amostras forem obtidas para uma base de dados, maior a tendência de se obter modelos mais adequados”.
>> Na maioria dos casos essa é verdadeira. Ter mais amostras em um modelo ajuda a IA a entender o padrão de dados que está sendo usado como base, assim , o risco de overfitting se torna menor. Contudo, se tivemos uma baixa quantidade de amostras, e essas ainda forem de qualidade baixa, ou seja , muitos erros, nessa situação o modelo pode não resultar em um compilado confiável.

c. “Às vezes com simples manipulações na base de dados (limpeza, conversão de valores, etc.) pode-se conseguir melhoras significativas nos resultados, sem fazer
nenhuma alteração na técnica de aprendizado de máquina usada”.
>> Essa é verdadeira na maioria dos casos. Dados com grande qualidade são de extrema importância para o modelo. A ação de limpar os dados, corrigir valores, pode melhorar de forma substancial o desempenho, mesmo não mudando o algoritmo.
/*--------------------------------------------------------------------------------------------------------------------------------------------------------------------------*/
6. Em uma empresa é adotado um método de Aprendizado de Máquina para detectar defeito de
fabricação de peças mecânicas, sendo que raramente acontece este tipo de problema na fábrica. Um funcionário anuncia empolgado que o sistema alcançou uma acurácia de 99%, porém seu gerente não achou o resultado tão relevante. Responda:
a. Por que o gerente não ficou empolgado com o resultado achado?
>> Acreditamos que o gerente não tenha ficado tão contente com o resultado , porque mesmo com um número alto de acurácia, isso pode depender muito da situação que este resultado foi retirado. No caso, se os defeitos das peças forem um cenário raro, que só aconteça 1%, o modelo poderia dizer que todas as peças estão boas , sem realmente verificar se existem peças com defeito. Dessa forma, se a acurácia dor alta, o modelo pode não estar identificando corretamente os casos problemáticos, que é justamente oque importa no contexto.

b. O que o funcionário poderia fazer para confirmar se o método empregado é
adequado para o problema?
>>  Nesse caso, pra ter certeza se o método está realmente funcionando, além de analisar a acurácia, analisar também outras métricas, como o recall (mapeando os defeitos que o modelo talvez não esteja encontrando) e a precisão, se o modelo diz que algo está correto e realmente verificar se está correto, seria uma dupla verificação. Outro método também utilizado pode ser a matriz de confusão, com outras técnicas de validação de dados cruzados, para verificar se as previsões estão corretas.
/*--------------------------------------------------------------------------------------------------------------------------------------------------------------------------*/
7. Como pode ser usada uma árvore (de regressão ou de decisão) para avaliar uma amostra quando ela possui uma ou mais variáveis faltantes?
>> Em relação a árvore de decisão, ou regressão com variáveis faltantes, conseguimos dar prosseguimento no desenvolvimento do modelo sem todas as informações. No caso de se faltar uma variável em algum ponto da árvore, pela tomada de decisões vão surgindo caminhos alternativos. Existem certas árvores que fazem isso automaticamente se ajustando com o que se tem disponível.
Outra alternativa é substituir valores por médias, tendo assim todos os campos preenchidos. Os modelos mais avançados de árvores conseguem realizar as divisões dos valores faltantes de modo inteligente sem que isso acarrete em desvios bruscos no seu resultado. Assim, mesmo tendo dados incompletos ou ausentes, as árvores de decisão e regressão classificam de forma específica e eficiente.






